{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Approach - Word Embedding - keras one_hot() - cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Hitesh\n",
      "[nltk_data]     khatana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot , Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>Selfie</th>\n",
       "      <th>couple</th>\n",
       "      <th>question</th>\n",
       "      <th>Winter</th>\n",
       "      <th>summer</th>\n",
       "      <th>spring</th>\n",
       "      <th>food</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I never let my friends do stupid thingsalone!</td>\n",
       "      <td>In this section, we include funny Instagram ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Where do you travel next?</td>\n",
       "      <td>To appreciate the beauty of a snowflake it is ...</td>\n",
       "      <td>This summer fashion? My bikini!,</td>\n",
       "      <td>April showers bring May flowers.</td>\n",
       "      <td>I like people that protect their food like it...</td>\n",
       "      <td>Catch flights, not feelings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dogs are real friends of a human being</td>\n",
       "      <td>My excuse is that I'm young.</td>\n",
       "      <td>I'm not perfect, I'm original.</td>\n",
       "      <td>What made you fall for him? He never asked me ...</td>\n",
       "      <td>Have you ever been to Bali?</td>\n",
       "      <td>Give me a hot drink, and Im happy. Hot cider, ...</td>\n",
       "      <td>Less Monday, More Summer.,</td>\n",
       "      <td>O, wind, if winter comes, can spring be far be...</td>\n",
       "      <td>#foodporn</td>\n",
       "      <td>Travel is fatal to prejudice, bigotry, and nar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         friends  \\\n",
       "0  I never let my friends do stupid thingsalone!   \n",
       "1         Dogs are real friends of a human being   \n",
       "\n",
       "                                               funny  \\\n",
       "0  In this section, we include funny Instagram ca...   \n",
       "1                       My excuse is that I'm young.   \n",
       "\n",
       "                           Selfie  \\\n",
       "0                             NaN   \n",
       "1  I'm not perfect, I'm original.   \n",
       "\n",
       "                                              couple  \\\n",
       "0                                                NaN   \n",
       "1  What made you fall for him? He never asked me ...   \n",
       "\n",
       "                      question  \\\n",
       "0    Where do you travel next?   \n",
       "1  Have you ever been to Bali?   \n",
       "\n",
       "                                              Winter  \\\n",
       "0  To appreciate the beauty of a snowflake it is ...   \n",
       "1  Give me a hot drink, and Im happy. Hot cider, ...   \n",
       "\n",
       "                             summer  \\\n",
       "0  This summer fashion? My bikini!,   \n",
       "1        Less Monday, More Summer.,   \n",
       "\n",
       "                                              spring  \\\n",
       "0                   April showers bring May flowers.   \n",
       "1  O, wind, if winter comes, can spring be far be...   \n",
       "\n",
       "                                                food  \\\n",
       "0   I like people that protect their food like it...   \n",
       "1                                          #foodporn   \n",
       "\n",
       "                                              travel  \n",
       "0                       Catch flights, not feelings.  \n",
       "1  Travel is fatal to prejudice, bigotry, and nar...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"caption_data.csv\")\n",
    "full_data[\"friends\"][1] = \"Dogs are real friends of a human being\"\n",
    "full_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values to zero\n",
    "# remove stopwords\n",
    "# returns filtered data and vocabalry size\n",
    "def preprocessing(data):\n",
    "    for column in data.columns:\n",
    "        data[column] = data[column].fillna(0)\n",
    "    vocab = 0\n",
    "    for column in data.columns:\n",
    "        for i in range(0,len(data)):\n",
    "            filter_words = []\n",
    "            for words in str(data[column][i]).lower().split():\n",
    "                if words not in stopwords.words('english'):\n",
    "                    filter_words.append(words)\n",
    "                    vocab += 1\n",
    "            data[column][i] = \" \".join(filter_words)\n",
    "    return data , vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding with keras one_hot function but unicity is not guaranteed in keras one_hot function.\n",
    "def one_hot_func(data , vocab):\n",
    "    final = []\n",
    "    for column in data.columns:\n",
    "        col_rep = []\n",
    "        for sent in data[column]:\n",
    "            sent_rep = one_hot(sent , vocab)\n",
    "            col_rep.append(sent_rep)\n",
    "        final.append(col_rep)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedds the data with specific sentence length.\n",
    "def embedd(final):\n",
    "    sent_length=50\n",
    "    embedded = []\n",
    "    for col in range(0,np.array(final).shape[0]):\n",
    "        c_embed = []\n",
    "        for i in range(0,np.array(final).shape[1]):\n",
    "            embedded_docs = pad_sequences([final[col][i]],padding='pre',maxlen=sent_length)\n",
    "            c_embed.append(embedded_docs)\n",
    "        embedded.append(c_embed)\n",
    "    return embedded , sent_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron model for predicting vectors.\n",
    "#here \"100\" is number of features for every input.\n",
    "def vector_model(embedded , vocab , sent_length):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab,100,input_length=sent_length))\n",
    "    model.compile('adam','mse')\n",
    "    \n",
    "    \n",
    "    vectors = []\n",
    "    for col in range(0, np.array(embedded).shape[0]):\n",
    "        col_v = []\n",
    "        for i in range(0,np.array(embedded).shape[1]):\n",
    "            col_vectors = model.predict(embedded[col][i])\n",
    "            col_v.append(col_vectors)\n",
    "        vectors.append(col_v)\n",
    "    return vectors , model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data from object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(data , target_value):\n",
    "    data[\"target\"] = pd.Series([target_value])\n",
    "    data , vocab = preprocessing(data)\n",
    "    \n",
    "    final = one_hot_func(data , vocab)\n",
    "    \n",
    "    embedded , sent_length = embedd(final)\n",
    "    \n",
    "    vectors , model = vector_model(embedded , vocab , sent_length)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \" dogs person\"\n",
    "vectors = test_data(full_data.copy() , target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 27, 1, 50, 100)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns cosine similarity between two vectors\n",
    "def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n",
    "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " get genre from 'friends', 'funny', 'Selfie', 'couple', 'question', 'Winter', 'summer',\n",
    "       'spring', 'food', 'travel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict cosine similarity between target vector and captions vector\n",
    "# returns top 5 vectors having maximum vectors..\n",
    "# input (caption data , vectors , genre provided to search in specific column)\n",
    "def predict(data , vectors ,genre):\n",
    "    column = data.columns.get_loc(genre)\n",
    "    result = []\n",
    "    test_vector = vectors[10][0]\n",
    "    for i in range(0,data.shape[0]):\n",
    "        result.append(get_cosine_similarity(test_vector,vectors[column][i]))\n",
    "        \n",
    "        \n",
    "    indexes = np.argsort(np.array(result))[-5:]\n",
    "    \n",
    "    \n",
    "    return data[genre].loc[indexes] , result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "result , res = predict(full_data , vectors , \"friends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.index(max(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I never let my friends do stupid thingsalone!'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[\"friends\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    I and my best friend can communicate with just...\n",
       "22    You had me at We'll make it look like an accid...\n",
       "6     You have to be crazy to hang out with me I'll ...\n",
       "5     I know what tighter, our jeans or our friendship.\n",
       "1                Dogs are real friends of a human being\n",
       "Name: friends, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_ = result\n",
    "keras_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Approach - Word embedding - One-hot encoding using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary(data):\n",
    "    for column in data.columns:\n",
    "        data[column] = data[column].fillna(0)\n",
    "    vocab = 0\n",
    "    all_words = []\n",
    "    for column in data.columns:\n",
    "        for i in range(0 ,len(data)):\n",
    "            filter_words = []\n",
    "            for words in str(data[column][i]).lower().split():\n",
    "                if words not in stopwords.words('english'):\n",
    "                    all_words.append(words)\n",
    "                    filter_words.append(words)\n",
    "                    vocab += 1\n",
    "                    \n",
    "            data[column][i] = \" \".join(filter_words)\n",
    "    all_words = \" \".join(all_words)    \n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts([all_words])\n",
    "    \n",
    "    \n",
    "    return t.word_index , vocab , data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(dic ,data):\n",
    "    e_whole = []\n",
    "    for column in data.columns:\n",
    "        e_column = []\n",
    "        for sent in data[column]:\n",
    "            e_sent = []\n",
    "            for word in sent.split():\n",
    "                try:\n",
    "                    word = re.sub(r\"[^a-zA-Z0-9]+\", '', word)\n",
    "                    e_sent.append(int(dic[word]))\n",
    "                except:\n",
    "                    continue\n",
    "                   \n",
    "            e_column.append(e_sent)\n",
    "        e_whole.append(e_column)\n",
    "            \n",
    "    return e_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd(final):\n",
    "    sent_length=50\n",
    "    embedded = []\n",
    "    for column in final:\n",
    "        emb_column = []\n",
    "        for sentence in column:\n",
    "            embedded_sent = pad_sequences([sentence],padding='pre',maxlen=sent_length)\n",
    "            emb_column.append(embedded_sent)\n",
    "        embedded.append(emb_column)\n",
    "    return embedded , sent_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_model(data , embedded , vocab , sent_length):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab,80,input_length=sent_length))\n",
    "    model.compile('adam','mse')\n",
    "    \n",
    "    \n",
    "    vectors = []\n",
    "    for col in range(0,data.shape[0]):\n",
    "        c_vectors = []\n",
    "        for i in range(0,data.shape[1]):\n",
    "            col_vectors = model.predict(embedded[i])\n",
    "            c_vectors.append(col_vectors)\n",
    "        vectors.append(c_vectors)\n",
    "    return vectors , model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(data , target_value):\n",
    "    data[\"target\"] = pd.Series([target_value])\n",
    "    dic , vocab ,filtered= dictionary(data)\n",
    "\n",
    "    encoded_result = one_hot_encoding(dic , filtered)\n",
    "    \n",
    "    embedded , sent_length = embedd(encoded_result)\n",
    "    \n",
    "    vectors , model = vector_model(data , embedded , vocab , sent_length)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------- target from object detection -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"dog person\"\n",
    "vectors = test_data(full_data.copy() , target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n",
    "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data , vectors ,genre):\n",
    "    column = data.columns.get_loc(genre)\n",
    "    test_vector = vectors[0][10]\n",
    "    result = []\n",
    "    for i in range(0,data.shape[0]):\n",
    "        result.append(get_cosine_similarity(test_vector,vectors[i][column]))\n",
    "        \n",
    "    indexes = np.argsort(np.array(result))[-5:]\n",
    "    \n",
    "    \n",
    "    return data[genre].loc[indexes] , result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 11, 1, 50, 80)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "result , res = predict(full_data , vectors , \"friends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.index(max(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.index(max(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     Friendship is like peeing on yourself: everyon...\n",
       "2     I like to hang out with people who make me for...\n",
       "1                Dogs are real friends of a human being\n",
       "12    Pay close attention to people who clap when yo...\n",
       "26    walk behind me; I may not lead. walk in front ...\n",
       "Name: friends, dtype: object"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_ = result\n",
    "dic_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Approach - spacy Library - Pretrained model(en_core_Web_leg)\n",
    "## [ Model contains 1 M word vectors.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Hitesh\n",
      "[nltk_data]     khatana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    vocab = 0\n",
    "    for column in data.columns:\n",
    "        data[column] = data[column].fillna(0)\n",
    "        for i in range(0,len(data)):\n",
    "            filter_words = []\n",
    "            for words in str(data[column][i]).lower().split():\n",
    "                if words not in stopwords.words('english'):\n",
    "                    filter_words.append(words)\n",
    "            \n",
    "                    vocab += 1\n",
    "            data[column][i] = \" \".join(filter_words)\n",
    "            \n",
    "    return data , vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions , vocab = preprocessing(full_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>Selfie</th>\n",
       "      <th>couple</th>\n",
       "      <th>question</th>\n",
       "      <th>Winter</th>\n",
       "      <th>summer</th>\n",
       "      <th>spring</th>\n",
       "      <th>food</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never let friends stupid thingsalone!</td>\n",
       "      <td>section, include funny instagram captions shor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>travel next?</td>\n",
       "      <td>appreciate beauty snowflake necessary stand co...</td>\n",
       "      <td>summer fashion? bikini!,</td>\n",
       "      <td>april showers bring may flowers.</td>\n",
       "      <td>like people protect food like would baby.</td>\n",
       "      <td>catch flights, feelings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dogs real friends human</td>\n",
       "      <td>excuse i'm young.</td>\n",
       "      <td>i'm perfect, i'm original.</td>\n",
       "      <td>made fall him? never asked justify past.</td>\n",
       "      <td>ever bali?</td>\n",
       "      <td>give hot drink, im happy. hot cider, hot choco...</td>\n",
       "      <td>less monday, summer.,</td>\n",
       "      <td>o, wind, winter comes, spring far behind?</td>\n",
       "      <td>#foodporn</td>\n",
       "      <td>travel fatal prejudice, bigotry, narrow minded...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 friends  \\\n",
       "0  never let friends stupid thingsalone!   \n",
       "1                dogs real friends human   \n",
       "\n",
       "                                               funny  \\\n",
       "0  section, include funny instagram captions shor...   \n",
       "1                                  excuse i'm young.   \n",
       "\n",
       "                       Selfie                                    couple  \\\n",
       "0                           0                                         0   \n",
       "1  i'm perfect, i'm original.  made fall him? never asked justify past.   \n",
       "\n",
       "       question                                             Winter  \\\n",
       "0  travel next?  appreciate beauty snowflake necessary stand co...   \n",
       "1    ever bali?  give hot drink, im happy. hot cider, hot choco...   \n",
       "\n",
       "                     summer                                     spring  \\\n",
       "0  summer fashion? bikini!,           april showers bring may flowers.   \n",
       "1     less monday, summer.,  o, wind, winter comes, spring far behind?   \n",
       "\n",
       "                                        food  \\\n",
       "0  like people protect food like would baby.   \n",
       "1                                  #foodporn   \n",
       "\n",
       "                                              travel  \n",
       "0                           catch flights, feelings.  \n",
       "1  travel fatal prejudice, bigotry, narrow minded...  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(nlp , column , test):\n",
    "    test_vector = nlp(test)\n",
    "    result = []\n",
    "    for caption in column:\n",
    "        result.append(test_vector.similarity(nlp(caption)))\n",
    "        \n",
    "        \n",
    "    indexes = np.argsort(np.array(result))[-5:]\n",
    "    \n",
    "    return indexes , result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes , result = predict(nlp , full_data[\"friends\"] , \"dog person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 10, 13, 17,  1], dtype=int64)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    Walking with a friend in the dark is better th...\n",
       "10    It takes a long time to grow an old friend. “ ...\n",
       "13    A real friend is one who walks in when the res...\n",
       "17    Friends can help each other. A true friend is ...\n",
       "1                Dogs are real friends of a human being\n",
       "Name: friends, dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_ = full_data[\"friends\"].loc[indexes]\n",
    "spacy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.index(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     Friendship is like peeing on yourself: everyon...\n",
       "2     I like to hang out with people who make me for...\n",
       "1                Dogs are real friends of a human being\n",
       "12    Pay close attention to people who clap when yo...\n",
       "26    walk behind me; I may not lead. walk in front ...\n",
       "Name: friends, dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    I and my best friend can communicate with just...\n",
       "22    You had me at We'll make it look like an accid...\n",
       "6     You have to be crazy to hang out with me I'll ...\n",
       "5     I know what tighter, our jeans or our friendship.\n",
       "1                Dogs are real friends of a human being\n",
       "Name: friends, dtype: object"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    Walking with a friend in the dark is better th...\n",
       "10    It takes a long time to grow an old friend. “ ...\n",
       "13    A real friend is one who walks in when the res...\n",
       "17    Friends can help each other. A true friend is ...\n",
       "1                Dogs are real friends of a human being\n",
       "Name: friends, dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Spacy pretrained model is the fastest and most accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
